{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df =pd.read_csv( 'https://query.data.world/s/wh6j7rxy2hvrn4ml75ci62apk5hgae' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaPerCap</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.097188051</td>\n",
       "      <td>0.036888</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.032351e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>483000.000000</td>\n",
       "      <td>687000.000000</td>\n",
       "      <td>334600</td>\n",
       "      <td>127000.000000</td>\n",
       "      <td>100943.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732543e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.135261</td>\n",
       "      <td>0.084003213</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.262086e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>550176.242700</td>\n",
       "      <td>465677.972200</td>\n",
       "      <td>289207.1078</td>\n",
       "      <td>47311.551720</td>\n",
       "      <td>114982.279300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467355e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>0.387510</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>1.26E-06</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>1.114093</td>\n",
       "      <td>1.728629e+00</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year  country_code        record      crop_land   grazing_land  \\\n",
       "0  Armenia  1992             1    AreaPerCap       0.140292       0.199546   \n",
       "1  Armenia  1992             1     AreaTotHA  483000.000000  687000.000000   \n",
       "2  Armenia  1992             1  BiocapPerCap       0.159804       0.135261   \n",
       "3  Armenia  1992             1  BiocapTotGHA  550176.242700  465677.972200   \n",
       "4  Armenia  1992             1  EFConsPerCap       0.387510       0.189462   \n",
       "\n",
       "   forest_land  fishing_ground  built_up_land    carbon         total QScore  \n",
       "0  0.097188051        0.036888       0.029320  0.000000  5.032351e-01     3A  \n",
       "1       334600   127000.000000  100943.000800  0.000000  1.732543e+06     3A  \n",
       "2  0.084003213        0.013742       0.033398  0.000000  4.262086e-01     3A  \n",
       "3  289207.1078    47311.551720  114982.279300  0.000000  1.467355e+06     3A  \n",
       "4     1.26E-06        0.004165       0.033398  1.114093  1.728629e+00     3A  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'country_code', 'record', 'crop_land',\n",
       "       'grazing_land', 'forest_land', 'fishing_ground', 'built_up_land',\n",
       "       'carbon', 'total', 'QScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country            object\n",
       "year                int64\n",
       "country_code        int64\n",
       "record             object\n",
       "crop_land         float64\n",
       "grazing_land      float64\n",
       "forest_land        object\n",
       "fishing_ground    float64\n",
       "built_up_land     float64\n",
       "carbon            float64\n",
       "total             float64\n",
       "QScore             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51481\n",
       "2A    10576\n",
       "2B    10096\n",
       "1A       16\n",
       "1B       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country               0\n",
       "year                  0\n",
       "country_code          0\n",
       "record                0\n",
       "crop_land         20472\n",
       "grazing_land      20472\n",
       "forest_land       20472\n",
       "fishing_ground    20473\n",
       "built_up_land     20473\n",
       "carbon            20473\n",
       "total                 9\n",
       "QScore                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72186 entries, 0 to 72185\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   country         72186 non-null  object \n",
      " 1   year            72186 non-null  int64  \n",
      " 2   country_code    72186 non-null  int64  \n",
      " 3   record          72186 non-null  object \n",
      " 4   crop_land       51714 non-null  float64\n",
      " 5   grazing_land    51714 non-null  float64\n",
      " 6   forest_land     51714 non-null  object \n",
      " 7   fishing_ground  51713 non-null  float64\n",
      " 8   built_up_land   51713 non-null  float64\n",
      " 9   carbon          51713 non-null  float64\n",
      " 10  total           72177 non-null  float64\n",
      " 11  QScore          72185 non-null  object \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df   =   df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country           0\n",
       "year              0\n",
       "country_code      0\n",
       "record            0\n",
       "crop_land         0\n",
       "grazing_land      0\n",
       "forest_land       0\n",
       "fishing_ground    0\n",
       "built_up_land     0\n",
       "carbon            0\n",
       "total             0\n",
       "QScore            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      224\n",
       "1A       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ 'QScore' ]   =   df[ 'QScore' ].replace([ '1A' ],    '2A' )  \n",
    "df.QScore.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51713, 12)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2A   =   df[df.QScore== '2A' ]  \n",
    "df_3A   =   df[df.QScore== '3A' ].sample( 350 )  \n",
    "data_df   =   df_2A.append(df_3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 12)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590, 12),\n",
       " 3A    350\n",
       " 2A    240\n",
       " Name: QScore, dtype: int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  sklearn.utils  \n",
    "data_df = sklearn.utils.shuffle(data_df)  \n",
    "data_df =  data_df.reset_index(drop= True )  \n",
    "data_df.shape  ,data_df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=data_df.drop(columns=[ 'country_code' ,    'country' ,    'year' ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X   =   data_df.drop(columns= 'QScore' )  \n",
    "y   =   data_df[ 'QScore' ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    248\n",
       "2A    165\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from    sklearn.model_selection    import    train_test_split  \n",
    "x_train,   x_test,   y_train,   y_test   =   train_test_split(X,   y,   test_size= 0.3 ,   random_state= 0 )  \n",
    "y_train.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "from    sklearn.preprocessing    import    LabelEncoder  \n",
    "encoder   =   LabelEncoder()  \n",
    "x_train.record   =   encoder.fit_transform(x_train.record)  \n",
    "x_test.record   =   encoder.transform(x_test.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    102\n",
       "2A     75\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.18.5)\n",
      "Collecting scikit-learn>=0.24\n",
      "  Using cached scikit_learn-1.0-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.8.0 scikit-learn-1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import    imblearn  \n",
    "from    imblearn.over_sampling    import    SMOTE  \n",
    "smote   =   SMOTE(random_state= 1 )  \n",
    "x_train_balanced, y_balanced=smote.fit_resample(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    sklearn.preprocessing    import    MinMaxScaler  \n",
    "scaler =MinMaxScaler()  \n",
    "normalised_train_df = scaler.fit_transform(x_train_balanced.drop(columns=[ 'record' ]))  \n",
    "normalised_train_df = pd.DataFrame(normalised_train_df,  \n",
    "columns=x_train_balanced.drop(columns=[ 'record' ]).columns)  \n",
    "normalised_train_df[ 'record' ] = x_train_balanced[ 'record' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.759000e+06</td>\n",
       "      <td>8.356000e+06</td>\n",
       "      <td>373537</td>\n",
       "      <td>2.369000e+05</td>\n",
       "      <td>2.683810e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.499382e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2.233827e+06</td>\n",
       "      <td>6.378623e+05</td>\n",
       "      <td>7.63563e+06</td>\n",
       "      <td>2.373449e+06</td>\n",
       "      <td>2.182641e+05</td>\n",
       "      <td>1.826655e+07</td>\n",
       "      <td>3.136558e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.770263e-01</td>\n",
       "      <td>6.542301e-02</td>\n",
       "      <td>0.069929</td>\n",
       "      <td>8.514426e-03</td>\n",
       "      <td>5.111223e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.072005e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8.003877e+05</td>\n",
       "      <td>2.405219e+05</td>\n",
       "      <td>2.20531e+06</td>\n",
       "      <td>6.617395e+04</td>\n",
       "      <td>1.385578e+05</td>\n",
       "      <td>2.614962e+05</td>\n",
       "      <td>3.712452e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2.390733e+04</td>\n",
       "      <td>1.858649e+02</td>\n",
       "      <td>1718.74</td>\n",
       "      <td>5.527165e+04</td>\n",
       "      <td>3.591599e+04</td>\n",
       "      <td>8.873066e+06</td>\n",
       "      <td>8.990066e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2</td>\n",
       "      <td>2.434509e-01</td>\n",
       "      <td>3.435680e-01</td>\n",
       "      <td>0.194474</td>\n",
       "      <td>6.679449e-02</td>\n",
       "      <td>5.445366e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.027412e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>5</td>\n",
       "      <td>1.353214e+07</td>\n",
       "      <td>1.311457e+06</td>\n",
       "      <td>819328</td>\n",
       "      <td>3.668690e+05</td>\n",
       "      <td>1.051084e+06</td>\n",
       "      <td>4.882906e+07</td>\n",
       "      <td>6.590994e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>3</td>\n",
       "      <td>1.660028e+05</td>\n",
       "      <td>8.670254e+04</td>\n",
       "      <td>1.25928e+06</td>\n",
       "      <td>9.290297e+05</td>\n",
       "      <td>3.951485e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.480534e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2</td>\n",
       "      <td>1.544531e+00</td>\n",
       "      <td>6.474341e-02</td>\n",
       "      <td>0.69833</td>\n",
       "      <td>7.675042e-03</td>\n",
       "      <td>1.585836e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.473863e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>2.944651e-01</td>\n",
       "      <td>5.755103e-02</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>7.497823e-02</td>\n",
       "      <td>2.382689e-02</td>\n",
       "      <td>1.366151e+00</td>\n",
       "      <td>1.981859e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record     crop_land  grazing_land  forest_land  fishing_ground  \\\n",
       "0         1  5.759000e+06  8.356000e+06       373537    2.369000e+05   \n",
       "1         7  2.233827e+06  6.378623e+05  7.63563e+06    2.373449e+06   \n",
       "2         2  8.770263e-01  6.542301e-02     0.069929    8.514426e-03   \n",
       "3         5  8.003877e+05  2.405219e+05  2.20531e+06    6.617395e+04   \n",
       "4         7  2.390733e+04  1.858649e+02      1718.74    5.527165e+04   \n",
       "..      ...           ...           ...          ...             ...   \n",
       "491       2  2.434509e-01  3.435680e-01     0.194474    6.679449e-02   \n",
       "492       5  1.353214e+07  1.311457e+06       819328    3.668690e+05   \n",
       "493       3  1.660028e+05  8.670254e+04  1.25928e+06    9.290297e+05   \n",
       "494       2  1.544531e+00  6.474341e-02      0.69833    7.675042e-03   \n",
       "495       4  2.944651e-01  5.755103e-02     0.164887    7.497823e-02   \n",
       "\n",
       "     built_up_land        carbon         total  \n",
       "0     2.683810e+05  0.000000e+00  1.499382e+07  \n",
       "1     2.182641e+05  1.826655e+07  3.136558e+07  \n",
       "2     5.111223e-02  0.000000e+00  1.072005e+00  \n",
       "3     1.385578e+05  2.614962e+05  3.712452e+06  \n",
       "4     3.591599e+04  8.873066e+06  8.990066e+06  \n",
       "..             ...           ...           ...  \n",
       "491   5.445366e-02  0.000000e+00  9.027412e-01  \n",
       "492   1.051084e+06  4.882906e+07  6.590994e+07  \n",
       "493   3.951485e+04  0.000000e+00  2.480534e+06  \n",
       "494   1.585836e-01  0.000000e+00  2.473863e+00  \n",
       "495   2.382689e-02  1.366151e+00  1.981859e+00  \n",
       "\n",
       "[496 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2A    248\n",
       "3A    248\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_balanced.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from    sklearn.linear_model    import    LogisticRegression  \n",
    "log_reg   =   LogisticRegression()  \n",
    "log_reg.fit(normalised_train_df,   y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5649717514124294"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics as met\n",
    "\n",
    "met.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53703704, 0.5235023 , 0.51556481, 0.51271534, 0.51707317])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from    sklearn.model_selection    import    cross_val_score  \n",
    "scores   =   cross_val_score(log_reg,   normalised_train_df,   y_balanced,   cv= 5 ,   scoring= 'f1_macro' )  \n",
    "scores  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K - Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    sklearn.model_selection    import    KFold  \n",
    "from sklearn.metrics import f1_score\n",
    "kf   =   KFold(n_splits= 5 )  \n",
    "kf.split(normalised_train_df)   \n",
    "f1_scores   =   []  \n",
    "#run   for   every   split  \n",
    "for train_index,test_index in kf.split(normalised_train_df):  \n",
    "    x_train, x_test   =   normalised_train_df.iloc[train_index],normalised_train_df.iloc[test_index]  \n",
    "    y_train, y_test   =   y_balanced[train_index],  y_balanced[test_index]  \n",
    "    model   =   LogisticRegression().fit(x_train,   y_train)  \n",
    "   #save   result   to   list  \n",
    "    f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test),   \n",
    "                    pos_label= '2A' )* 100 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.0, 54.54545454545454, 51.42857142857144, 54.39999999999999, 0.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    sklearn.model_selection    import    StratifiedKFold  \n",
    "skf   =   StratifiedKFold(n_splits= 5 ,   shuffle= True ,   random_state= 1 ) \n",
    "f1_scores   =   []  \n",
    "#run   for   every   split  \n",
    "for    train_index,   test_index    in    skf.split(normalised_train_df,   y_balanced):  \n",
    "    x_train,   x_test   =   np.array(normalised_train_df)[train_index],np.array(normalised_train_df)[test_index]  \n",
    "    y_train,   y_test    =   y_balanced[train_index], y_balanced[test_index]  \n",
    "    model   =   LogisticRegression().fit(x_train,   y_train)  \n",
    "    #save   result   to   list  \n",
    "    f1_scores.append(f1_score(y_true=y_test,   y_pred=model.predict(x_test), pos_label='2A')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5148514851485149,\n",
       " 0.6356589147286822,\n",
       " 0.5490196078431372,\n",
       " 0.5714285714285715,\n",
       " 0.5242718446601942]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  14,\n",
      "        15,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,\n",
      "        30,  31,  33,  34,  35,  36,  37,  38,  39,  40,  43,  44,  46,\n",
      "        47,  48,  49,  50,  51,  54,  56,  59,  60,  61,  62,  64,  65,\n",
      "        66,  68,  74,  76,  79,  80,  82,  83,  84,  85,  86,  87,  88,\n",
      "        89,  90,  91,  93,  95,  96,  97,  98,  99, 100, 101, 102, 104,\n",
      "       105, 106, 107, 110, 111, 112, 113, 114, 116, 117, 119, 121, 122,\n",
      "       123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136,\n",
      "       137, 138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "       152, 153, 154, 155, 156, 160, 161, 162, 163, 166, 167, 168, 169,\n",
      "       170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "       197, 199, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
      "       213, 214, 215, 220, 221, 223, 224, 225, 227, 228, 229, 230, 232,\n",
      "       233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245,\n",
      "       246, 248, 249, 250, 251, 253, 254, 255, 258, 259, 260, 261, 262,\n",
      "       263, 264, 265, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277,\n",
      "       278, 280, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294,\n",
      "       296, 297, 298, 299, 300, 301, 303, 304, 305, 306, 309, 310, 313,\n",
      "       314, 315, 316, 317, 318, 319, 321, 323, 326, 328, 329, 331, 332,\n",
      "       333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "       350, 351, 352, 354, 355, 357, 358, 359, 361, 362, 363, 365, 366,\n",
      "       367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 388, 390, 391, 392, 393, 394, 395,\n",
      "       396, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
      "       411, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 425, 426,\n",
      "       428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440,\n",
      "       441, 442, 444, 446, 447, 448, 449, 450, 451, 452, 456, 458, 459,\n",
      "       461, 462, 464, 465, 466, 467, 468, 470, 471, 472, 473, 474, 475,\n",
      "       476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 489,\n",
      "       490, 491, 492, 493, 494, 495]), array([ 10,  13,  23,  29,  32,  41,  42,  45,  52,  53,  55,  57,  58,\n",
      "        63,  67,  69,  70,  71,  72,  73,  75,  77,  78,  81,  92,  94,\n",
      "       103, 108, 109, 115, 118, 120, 132, 140, 141, 157, 158, 159, 164,\n",
      "       165, 171, 198, 200, 202, 216, 217, 218, 219, 222, 226, 231, 247,\n",
      "       252, 256, 257, 266, 272, 279, 281, 282, 293, 295, 302, 307, 308,\n",
      "       311, 312, 320, 322, 324, 325, 327, 330, 336, 347, 348, 349, 353,\n",
      "       356, 360, 364, 370, 387, 389, 397, 399, 412, 418, 424, 427, 443,\n",
      "       445, 453, 454, 455, 457, 460, 463, 469, 486])), (array([  1,   2,   3,   5,   6,   8,   9,  10,  13,  16,  17,  18,  19,\n",
      "        20,  21,  23,  25,  26,  27,  29,  30,  31,  32,  33,  34,  35,\n",
      "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  48,  49,\n",
      "        50,  51,  52,  53,  54,  55,  56,  57,  58,  60,  61,  62,  63,\n",
      "        64,  65,  66,  67,  69,  70,  71,  72,  73,  75,  76,  77,  78,\n",
      "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 102, 103, 105, 107, 108, 109, 111,\n",
      "       112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127,\n",
      "       128, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 143, 144,\n",
      "       146, 147, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "       162, 163, 164, 165, 166, 167, 170, 171, 172, 173, 175, 176, 178,\n",
      "       179, 181, 182, 183, 184, 185, 186, 187, 188, 190, 192, 193, 194,\n",
      "       195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209,\n",
      "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 236, 237,\n",
      "       240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "       253, 254, 256, 257, 258, 259, 261, 262, 264, 265, 266, 269, 270,\n",
      "       271, 272, 275, 276, 277, 279, 280, 281, 282, 283, 284, 286, 287,\n",
      "       288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 301, 302,\n",
      "       303, 304, 305, 307, 308, 309, 311, 312, 314, 317, 318, 319, 320,\n",
      "       322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334,\n",
      "       335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348,\n",
      "       349, 353, 354, 355, 356, 358, 359, 360, 363, 364, 366, 367, 368,\n",
      "       369, 370, 374, 375, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
      "       388, 389, 390, 392, 393, 395, 396, 397, 398, 399, 401, 403, 406,\n",
      "       407, 409, 410, 411, 412, 414, 416, 417, 418, 419, 420, 421, 423,\n",
      "       424, 426, 427, 428, 429, 430, 432, 433, 434, 437, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 452, 453, 454, 455,\n",
      "       457, 458, 459, 460, 461, 462, 463, 464, 466, 467, 468, 469, 470,\n",
      "       471, 472, 473, 474, 475, 476, 477, 480, 481, 482, 483, 484, 485,\n",
      "       486, 487, 489, 492, 493, 494, 495]), array([  0,   4,   7,  11,  12,  14,  15,  22,  24,  28,  47,  59,  68,\n",
      "        74,  79,  90,  91, 101, 104, 106, 110, 116, 117, 125, 129, 131,\n",
      "       138, 142, 145, 148, 149, 151, 168, 169, 174, 177, 180, 189, 191,\n",
      "       196, 208, 233, 235, 238, 239, 255, 260, 263, 267, 268, 273, 274,\n",
      "       278, 285, 296, 300, 306, 310, 313, 315, 316, 321, 344, 350, 351,\n",
      "       352, 357, 361, 362, 365, 371, 372, 373, 376, 377, 378, 391, 394,\n",
      "       400, 402, 404, 405, 408, 413, 415, 422, 425, 431, 435, 436, 438,\n",
      "       451, 456, 465, 478, 479, 488, 490, 491])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  13,\n",
      "        14,  15,  17,  18,  20,  21,  22,  23,  24,  25,  26,  28,  29,\n",
      "        30,  32,  33,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
      "        49,  50,  52,  53,  55,  56,  57,  58,  59,  60,  63,  65,  66,\n",
      "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "        81,  82,  83,  84,  86,  87,  88,  90,  91,  92,  93,  94,  95,\n",
      "        96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
      "       109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124,\n",
      "       125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "       140, 141, 142, 143, 144, 145, 148, 149, 150, 151, 152, 153, 155,\n",
      "       156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170,\n",
      "       171, 173, 174, 176, 177, 180, 181, 186, 189, 190, 191, 192, 193,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "       223, 224, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "       238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 250, 251, 252,\n",
      "       253, 254, 255, 256, 257, 260, 261, 263, 264, 266, 267, 268, 269,\n",
      "       272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286,\n",
      "       287, 288, 293, 295, 296, 297, 299, 300, 301, 302, 305, 306, 307,\n",
      "       308, 309, 310, 311, 312, 313, 315, 316, 317, 318, 320, 321, 322,\n",
      "       323, 324, 325, 326, 327, 329, 330, 332, 334, 335, 336, 337, 340,\n",
      "       341, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357,\n",
      "       358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 370, 371, 372,\n",
      "       373, 374, 375, 376, 377, 378, 380, 381, 383, 387, 388, 389, 391,\n",
      "       392, 394, 396, 397, 398, 399, 400, 402, 403, 404, 405, 407, 408,\n",
      "       410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 424,\n",
      "       425, 426, 427, 428, 429, 431, 432, 434, 435, 436, 437, 438, 439,\n",
      "       442, 443, 444, 445, 446, 447, 451, 453, 454, 455, 456, 457, 458,\n",
      "       460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "       473, 474, 475, 476, 477, 478, 479, 481, 482, 483, 484, 485, 486,\n",
      "       487, 488, 490, 491, 493, 494, 495]), array([  8,  16,  19,  27,  31,  34,  35,  36,  40,  48,  51,  54,  61,\n",
      "        62,  64,  80,  85,  89, 111, 113, 123, 127, 128, 146, 147, 154,\n",
      "       160, 167, 172, 175, 178, 179, 182, 183, 184, 185, 187, 188, 194,\n",
      "       209, 212, 225, 237, 242, 249, 258, 259, 262, 265, 270, 271, 275,\n",
      "       283, 289, 290, 291, 292, 294, 298, 303, 304, 314, 319, 328, 331,\n",
      "       333, 338, 339, 342, 345, 354, 355, 368, 369, 379, 382, 384, 385,\n",
      "       386, 390, 393, 395, 401, 406, 409, 419, 423, 430, 433, 440, 441,\n",
      "       448, 449, 450, 452, 459, 480, 489, 492])), (array([  0,   1,   2,   3,   4,   5,   7,   8,  10,  11,  12,  13,  14,\n",
      "        15,  16,  18,  19,  22,  23,  24,  25,  26,  27,  28,  29,  30,\n",
      "        31,  32,  34,  35,  36,  37,  38,  40,  41,  42,  43,  44,  45,\n",
      "        47,  48,  49,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
      "        61,  62,  63,  64,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "        75,  77,  78,  79,  80,  81,  85,  86,  87,  89,  90,  91,  92,\n",
      "        94,  95,  97,  98,  99, 101, 102, 103, 104, 105, 106, 108, 109,\n",
      "       110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 125, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141,\n",
      "       142, 143, 145, 146, 147, 148, 149, 151, 152, 154, 157, 158, 159,\n",
      "       160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175,\n",
      "       177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
      "       191, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 206,\n",
      "       208, 209, 211, 212, 216, 217, 218, 219, 220, 222, 224, 225, 226,\n",
      "       227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "       242, 244, 245, 247, 249, 250, 252, 253, 255, 256, 257, 258, 259,\n",
      "       260, 262, 263, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275,\n",
      "       278, 279, 281, 282, 283, 285, 289, 290, 291, 292, 293, 294, 295,\n",
      "       296, 297, 298, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310,\n",
      "       311, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "       339, 340, 342, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "       354, 355, 356, 357, 358, 360, 361, 362, 364, 365, 366, 367, 368,\n",
      "       369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 382, 383,\n",
      "       384, 385, 386, 387, 389, 390, 391, 392, 393, 394, 395, 397, 399,\n",
      "       400, 401, 402, 403, 404, 405, 406, 408, 409, 411, 412, 413, 414,\n",
      "       415, 416, 417, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428,\n",
      "       430, 431, 432, 433, 435, 436, 437, 438, 440, 441, 443, 445, 447,\n",
      "       448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 459, 460, 463,\n",
      "       465, 466, 467, 469, 472, 475, 476, 478, 479, 480, 482, 483, 485,\n",
      "       486, 488, 489, 490, 491, 492, 493]), array([  6,   9,  17,  20,  21,  33,  39,  46,  50,  65,  76,  82,  83,\n",
      "        84,  88,  93,  96, 100, 107, 112, 119, 121, 124, 126, 139, 144,\n",
      "       150, 153, 155, 156, 162, 163, 173, 176, 181, 192, 199, 205, 207,\n",
      "       210, 213, 214, 215, 221, 223, 229, 241, 243, 246, 248, 251, 254,\n",
      "       261, 264, 269, 276, 277, 280, 284, 286, 287, 288, 299, 301, 317,\n",
      "       329, 341, 343, 359, 363, 380, 381, 388, 396, 398, 407, 410, 421,\n",
      "       429, 434, 439, 442, 444, 446, 458, 461, 462, 464, 468, 470, 471,\n",
      "       473, 474, 477, 481, 484, 487, 494, 495])), (array([  0,   4,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,\n",
      "        17,  19,  20,  21,  22,  23,  24,  27,  28,  29,  31,  32,  33,\n",
      "        34,  35,  36,  39,  40,  41,  42,  45,  46,  47,  48,  50,  51,\n",
      "        52,  53,  54,  55,  57,  58,  59,  61,  62,  63,  64,  65,  67,\n",
      "        68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  84,  85,  88,  89,  90,  91,  92,  93,  94,  96,\n",
      "       100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 115,\n",
      "       116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129,\n",
      "       131, 132, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149,\n",
      "       150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164,\n",
      "       165, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "       180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 194, 196,\n",
      "       198, 199, 200, 202, 205, 207, 208, 209, 210, 212, 213, 214, 215,\n",
      "       216, 217, 218, 219, 221, 222, 223, 225, 226, 229, 231, 233, 235,\n",
      "       237, 238, 239, 241, 242, 243, 246, 247, 248, 249, 251, 252, 254,\n",
      "       255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "       268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
      "       281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "       294, 295, 296, 298, 299, 300, 301, 302, 303, 304, 306, 307, 308,\n",
      "       310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 324,\n",
      "       325, 327, 328, 329, 330, 331, 333, 336, 338, 339, 341, 342, 343,\n",
      "       344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357,\n",
      "       359, 360, 361, 362, 363, 364, 365, 368, 369, 370, 371, 372, 373,\n",
      "       376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 404,\n",
      "       405, 406, 407, 408, 409, 410, 412, 413, 415, 418, 419, 421, 422,\n",
      "       423, 424, 425, 427, 429, 430, 431, 433, 434, 435, 436, 438, 439,\n",
      "       440, 441, 442, 443, 444, 445, 446, 448, 449, 450, 451, 452, 453,\n",
      "       454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 468,\n",
      "       469, 470, 471, 473, 474, 477, 478, 479, 480, 481, 484, 486, 487,\n",
      "       488, 489, 490, 491, 492, 494, 495]), array([  1,   2,   3,   5,  18,  25,  26,  30,  37,  38,  43,  44,  49,\n",
      "        56,  60,  66,  86,  87,  95,  97,  98,  99, 102, 105, 114, 122,\n",
      "       130, 133, 134, 135, 136, 137, 143, 152, 161, 166, 170, 186, 190,\n",
      "       193, 195, 197, 201, 203, 204, 206, 211, 220, 224, 227, 228, 230,\n",
      "       232, 234, 236, 240, 244, 245, 250, 253, 297, 305, 309, 318, 323,\n",
      "       326, 332, 334, 335, 337, 340, 346, 358, 366, 367, 374, 375, 383,\n",
      "       392, 403, 411, 414, 416, 417, 420, 426, 428, 432, 437, 447, 466,\n",
      "       467, 472, 475, 476, 482, 483, 485, 493]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(skf.split(normalised_train_df, y_balanced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    sklearn.model_selection    import    LeaveOneOut, LeavePOut  \n",
    "loo   =   LeaveOneOut()  \n",
    "scores   =   cross_val_score(LogisticRegression(),   normalised_train_df,   y_balanced,   cv=loo,   \n",
    "                          scoring= 'f1_macro' )  \n",
    "average_score   =   scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.41129032258065"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpo = LeavePOut(p=3)\n",
    "scores1 =cross_val_score(LogisticRegression(), normalised_train_df, y_balanced , cv =lpo, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
